{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Retrieving Answers from MemDoc\n",
    "\n",
    "Steps:\n",
    "\n",
    "1. Create and Setup the Kernel with the appropriate model.\n",
    "2. Acquire the data.\n",
    "3. Load the data in Volatile Memory.\n",
    "4. Create the prompts.\n",
    "5. Ask questions and the get the result via using Recalling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "dotnet_interactive": {
     "language": "csharp"
    },
    "polyglot_notebook": {
     "kernelName": "csharp"
    },
    "vscode": {
     "languageId": "polyglot-notebook"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><div></div><div></div><div><strong>Installed Packages</strong><ul><li><span>Microsoft.SemanticKernel, 0.12.207.1-preview</span></li></ul></div></div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#r \"nuget: Microsoft.SemanticKernel, 0.12.207.1-preview\"\n",
    "\n",
    "using Microsoft.SemanticKernel;\n",
    "using Microsoft.SemanticKernel.SemanticFunctions;\n",
    "using Microsoft.SemanticKernel.KernelExtensions;\n",
    "using Microsoft.SemanticKernel.Orchestration;\n",
    "using Microsoft.SemanticKernel.Memory;\n",
    "using Microsoft.SemanticKernel.CoreSkills;\n",
    "\n",
    "using System.Net.Http;\n",
    "\n",
    "HttpClient httpClient = new();"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Kernel Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "dotnet_interactive": {
     "language": "csharp"
    },
    "polyglot_notebook": {
     "kernelName": "csharp"
    },
    "vscode": {
     "languageId": "polyglot-notebook"
    }
   },
   "outputs": [],
   "source": [
    "string apiKey = \".. Enter your Open AI Key.\";\n",
    "string model = \"text-davinci-003\";\n",
    "string orgId = \"\";"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "dotnet_interactive": {
     "language": "csharp"
    },
    "polyglot_notebook": {
     "kernelName": "csharp"
    },
    "vscode": {
     "languageId": "polyglot-notebook"
    }
   },
   "outputs": [],
   "source": [
    "using Microsoft.SemanticKernel.Memory;\n",
    "\n",
    "var kernel = new KernelBuilder()\n",
    "    .Configure(c =>\n",
    "    {\n",
    "        /* To Use: AzureOpenAI\n",
    "        if (useAzureOpenAI)\n",
    "        {\n",
    "            c.AddAzureTextEmbeddingGenerationService(\"ada\", \"text-embedding-ada-002\", azureEndpoint, apiKey);\n",
    "            c.AddAzureTextCompletionService(\"davinci\", model, azureEndpoint, apiKey);\n",
    "        }\n",
    "        */\n",
    "        c.AddOpenAITextEmbeddingGenerationService(\"ada\", \"text-embedding-ada-002\", apiKey);\n",
    "        c.AddOpenAITextCompletionService(\"text-davinci-003\", model, apiKey, orgId);\n",
    "    })\n",
    "    .WithMemoryStorage(new VolatileMemoryStore())\n",
    "    .Build();"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Acquisition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "dotnet_interactive": {
     "language": "csharp"
    },
    "polyglot_notebook": {
     "kernelName": "csharp"
    },
    "vscode": {
     "languageId": "polyglot-notebook"
    }
   },
   "outputs": [],
   "source": [
    "// Extract Mem Doc questions\n",
    "string url = \"https://gist.githubusercontent.com/MokoSan/ce5b4d5a6cca725385ebdadb377b36b0/raw/fc1f700bc2783852c14549194c2a3aaae0f80d43/MemdocQuestions.md\";\n",
    "var response = await httpClient.GetAsync(url);\n",
    "string content = await response.Content.ReadAsStringAsync();\n",
    "string[] split = content.Split(\"##\", StringSplitOptions.RemoveEmptyEntries | StringSplitOptions.TrimEntries);"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Up The Data in a Memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "dotnet_interactive": {
     "language": "csharp"
    },
    "polyglot_notebook": {
     "kernelName": "csharp"
    },
    "vscode": {
     "languageId": "polyglot-notebook"
    }
   },
   "outputs": [],
   "source": [
    "const string MemoryCollectionName = \"memdocQnA\";\n",
    "\n",
    "var memorySkill = new TextMemorySkill();\n",
    "kernel.ImportSkill(memorySkill);\n",
    "\n",
    "// Build a semantic function that saves info to memory\n",
    "const string SaveFunctionDefinition = @\"{{save $info}}\";\n",
    "var memorySaver = kernel.CreateSemanticFunction(SaveFunctionDefinition);\n",
    "\n",
    "var context = kernel.CreateNewContext();\n",
    "context[TextMemorySkill.CollectionParam] = MemoryCollectionName;\n",
    "\n",
    "for (int i = 0; i < split.Length; i++)\n",
    "{\n",
    "    context[TextMemorySkill.KeyParam] = $\"q{i}\";\n",
    "    context[\"info\"] = split[i];\n",
    "    await memorySaver.InvokeAsync(context);\n",
    "}\n",
    "\n",
    "/*\n",
    "// Memory can be stored alternatively like this:\n",
    "\n",
    "for (int i = 0; i < split.Length - 210; i++)\n",
    "{\n",
    "    await kernel.Memory.SaveInformationAsync(MemoryCollectionName, id: $\"q{i}\", text: split[i]);\n",
    "}\n",
    "*/"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## QnA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "dotnet_interactive": {
     "language": "csharp"
    },
    "polyglot_notebook": {
     "kernelName": "csharp"
    },
    "vscode": {
     "languageId": "polyglot-notebook"
    }
   },
   "outputs": [],
   "source": [
    "// Set up the Semantic Function.\n",
    "const string skPrompt = @\"\n",
    "{{recall $input}}\n",
    "---\n",
    "If the question is irrelevant to the topics above, reply 'I don't know'.\n",
    "Considering only the information above, which has been loaded from a document consisting of questions and answers, answer the following:\n",
    "Explain the answers with depth as if you are speaking to a junior performance engineer: \n",
    "Question: {{$input}}\n",
    "\n",
    "Answer:\";\n",
    "context[TextMemorySkill.LimitParam] = \"1\";\n",
    "context[TextMemorySkill.RelevanceParam] = \"0.7\";\n",
    "\n",
    "var chatFunction = kernel.CreateSemanticFunction(skPrompt, maxTokens: 400, temperature: 0.0);\n",
    "Func<string, Task> Chat = async (string query) =>\n",
    "{\n",
    "    context[\"input\"] = query;\n",
    "    var res = await chatFunction.InvokeAsync(context);\n",
    "    Console.WriteLine($\"{query}\\n >> {res}\");\n",
    "};"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generic Questions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "dotnet_interactive": {
     "language": "csharp"
    },
    "polyglot_notebook": {
     "kernelName": "csharp"
    },
    "vscode": {
     "languageId": "polyglot-notebook"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "What is a GC?\n",
      " >>  A GC, or Garbage Collector, is a process in computer programming that is responsible for managing the memory usage of a program. It does this by periodically scanning the memory of the program and reclaiming any memory that is no longer being used. This helps to ensure that the program runs efficiently and does not run out of memory.\n",
      "What are some definitive signs of performance issues?\n",
      " >>  Performance issues can be indicated by long suspensions, random long GC pauses, and most GCs occurring as full blocking GCs. Long suspensions occur when the application is taking longer than expected to complete a task. Random long GC pauses occur when the garbage collector is taking longer than expected to clean up memory. Full blocking GCs occur when the garbage collector is taking a long time to complete its task, blocking other processes from running. These are all signs that the application is not performing as expected and may need to be optimized.\n",
      "What is the meaning of life?\n",
      " >>  I don't know.\n",
      "What is GC suspension?\n",
      " >>  GC suspension is a process that occurs when the Garbage Collector pauses the execution of programs in order to reclaim memory. This is an important process for performance engineers to understand, as it can help them identify and address memory issues in their programs. By understanding how GC suspension works, performance engineers can optimize their programs to reduce the amount of time spent in GC suspension, which can improve overall performance.\n"
     ]
    }
   ],
   "source": [
    "await Chat(\"What is a GC?\");\n",
    "await Chat(\"What are some definitive signs of performance issues?\");\n",
    "await Chat(\"What is the meaning of life?\");\n",
    "await Chat(\"What is GC suspension?\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "dotnet_interactive": {
     "language": "csharp"
    },
    "polyglot_notebook": {
     "kernelName": "csharp"
    },
    "vscode": {
     "languageId": "polyglot-notebook"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "What is the ephemeral segment? Explain in as much depth as possible.\n",
      " >>  The ephemeral segment in the GC heap is a specific segment that holds the ephemeral generations (gen0 and gen1). It is designed to contain newly allocated objects and is never larger than a single segment, which simplifies the memory management and garbage collection process. The space after the last live object in the ephemeral segment is kept committed after a garbage collection cycle, which allows gen0 allocations to immediately use this space. This committed space in the ephemeral segment corresponds to the gen0 budget, which is why the GC commits more memory than the current heap size. This distinction is especially important in server GC scenarios with multiple heaps and large gen0 budgets, as it ensures that the ephemeral segment is always available for new allocations.\n",
      "Identifying all issues that performance engineers should focus their efforts.\n",
      " >>  Performance engineers should focus their efforts on identifying and resolving any performance issues that may arise in the application. This includes monitoring top-level application metrics such as concurrent requests handled, average, maximum, and P95 request latency. Additionally, performance engineers should measure factors that can affect the metrics and have top-level component metrics that indicate workload variations, such as tracking memory allocations during peak hours. This helps identify if the workload puts additional stress on the garbage collector (GC), which can be valuable in GC analysis. Finally, performance engineers should also look for any potential bottlenecks or areas of improvement in the application code, such as inefficient algorithms or inefficient data structures. By doing this, performance engineers can ensure that the application is running as efficiently as possible.\n"
     ]
    }
   ],
   "source": [
    "await Chat(\"What is the ephemeral segment? Explain in as much depth as possible.\"); \n",
    "await Chat(\"Identifying all issues that performance engineers should focus their efforts.\");"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Taking Traces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "dotnet_interactive": {
     "language": "csharp"
    },
    "polyglot_notebook": {
     "kernelName": "csharp"
    },
    "vscode": {
     "languageId": "polyglot-notebook"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "How do I take a GCCollectOnly trace? I am on Windows and want to take a top level trace. Please help!\n",
      " >>  To take a GCCollectOnly trace on Windows, you can use the PerfView tool. First, open a command prompt window and type in the following command: `perfview /GCCollectOnly /AcceptEULA /nogui collect`. This will start the trace. When you are done, press 's' in the PerfView command window to stop the trace. This will generate a trace file that you can analyze to identify any performance issues related to garbage collection.\n",
      "How do I take a top level trace using the PerfView command line?\n",
      " >>  To take a top level trace using the PerfView command line, you need to run the command `perfview /GCCollectOnly /AcceptEULA /nogui collect`. This will start the trace. When you are done, press `s` in the PerfView command window to stop the trace. This will collect a top level GC trace which can be used to analyze the performance of your application.\n",
      "How do I take a top level trace\n",
      " >>  To take a top level trace on Linux, you can use the dotnet trace collect command. This command requires the process ID (pid) of the process you want to trace, the output path for the trace file, and the duration of the trace. The profile option should be set to gc-collect to collect a top level GC trace. Once the command is executed, the trace will be collected and saved to the output path specified.\n",
      "How do I take a CPU based GC trace?\n",
      " >>  To take a CPU based GC trace, you can use the PerfView command line tool. This command will collect a GC trace for 10 minutes and include CPU events, thread events, image load events, profile events, and GC events. The command is: PerfView /nogui /KernelEvents=Process+Thread+ImageLoad+Profile /ClrEvents:GC+Stack /clrEventLevel=Informational /BufferSize:3000 /CircularMB:3000 /MaxCollectSec:600 collect gc-with-cpu.etl. This command will collect all the necessary events to get a CPU based GC trace. It will also set the buffer size to 3000 MB and the circular buffer size to 3000 MB, which will ensure that the trace is collected for 10 minutes.\n",
      "How do I take a thread time trace?\n",
      " >>  To take a thread time trace, you can use the PerfView.exe command line tool with the following parameters: /nogui /accepteula /StopOnGCSuspendOverMSec:200 /Process:A /DelayAfterTriggerSec:0 /CollectMultiple:3 /KernelEvents=ThreadTime /ClrEvents:GC+Stack /BufferSize:3000 /CircularMB:3000 /Merge:TRUE /ZIP:True collect. This will capture detailed information about what the GC thread is waiting for during the SuspendEE phase, which can help identify the cause of long suspensions during GC and aid in the debugging process. However, ThreadTime traces can be too voluminous and might cause your application to not run \"normal\" enough to exhibit the behavior you were debugging. In that case, you can replace ThreadTime with Default in the command line parameters to take a trace with default kernel events, which often would either reveal the problem or give you enough clues.\n"
     ]
    }
   ],
   "source": [
    "await Chat(\"How do I take a GCCollectOnly trace? I am on Windows and want to take a top level trace. Please help!\");\n",
    "await Chat(\"How do I take a top level trace using the PerfView command line?\");\n",
    "await Chat(\"How do I take a top level trace\"); \n",
    "await Chat(\"How do I take a CPU based GC trace?\");\n",
    "await Chat(\"How do I take a thread time trace?\"); "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pinning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "dotnet_interactive": {
     "language": "csharp"
    },
    "polyglot_notebook": {
     "kernelName": "csharp"
    },
    "vscode": {
     "languageId": "polyglot-notebook"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "What is pinning?\n",
      " >>  Pinning is a feature in .NET that allows objects to be marked as unpinned, indicating that they cannot be moved by the garbage collector. This means that the objects will remain in the same memory location, even when the garbage collector runs. Pinning can be used to improve performance by ensuring that objects are not moved around in memory, which can be costly. However, it can also cause fragmentation issues if pinned objects are promoted to higher generations, such as gen1 or gen2. To mitigate this, it is recommended to pin objects in already compacted portions of the heap and allocate batches of pinned objects instead of allocating and pinning objects individually. Additionally, in .NET 5, the Pinned Object Heap (POH) feature was introduced, allowing pinned objects to be allocated on a separate heap to reduce fragmentation.\n",
      "How do I reduce pinning?\n",
      " >>  To reduce pinning, you should try to minimize the amount of objects that need to be pinned. This can be done by avoiding the use of large objects, such as arrays, and by using objects that are not pinned by default, such as strings. Additionally, you should try to use objects that are pinned for the shortest amount of time possible. This can be done by releasing the objects as soon as they are no longer needed, and by using the “fixed” keyword to pin objects only when absolutely necessary. Finally, you should try to use the “fixed” keyword in a way that minimizes the amount of memory that is pinned, such as by pinning only a portion of an object. By following these steps, you can reduce the amount of pinning and minimize the impact of memory fragmentation.\n",
      "How do I improve pinning performance?\n",
      " >>  Improving pinning performance requires careful management of pinned objects. To minimize fragmentation and optimize memory utilization, it is important to ensure that only necessary objects are pinned and that they are unpinned as soon as possible. Additionally, it is important to ensure that pinned objects are not moved by the GC, as this can lead to additional fragmentation. Finally, it is important to monitor memory usage and fragmentation to ensure that pinning is not causing any performance issues.\n"
     ]
    }
   ],
   "source": [
    "await Chat(\"What is pinning?\");\n",
    "await Chat(\"How do I reduce pinning?\");\n",
    "await Chat(\"How do I improve pinning performance?\");"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Memory Footprint Issues"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "dotnet_interactive": {
     "language": "csharp"
    },
    "polyglot_notebook": {
     "kernelName": "csharp"
    },
    "vscode": {
     "languageId": "polyglot-notebook"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "How do I reduce my memory footprint? What are some topic metrics I should look at?\n",
      " >>  To reduce your memory footprint, you should look at the GC heap size histogram. This metric provides information about the distribution of memory allocations in the GC heap, helping you understand the memory usage patterns and identify opportunities for optimization. You can also look at other metrics such as the number of objects allocated, the number of objects freed, and the amount of time spent in garbage collection. By understanding these metrics, you can identify areas where you can reduce memory usage and improve performance.\n",
      "What metrics should I look at to address my memory issues.\n",
      " >>  To address memory issues, it is important to look at the top-level garbage collection metrics, such as the amount of memory allocated, the amount of memory freed, the number of objects created, and the number of objects destroyed. Additionally, it is important to consider the time taken for garbage collection operations, the number of garbage collection cycles, and the amount of memory used by the application. By analyzing these metrics in the context of the performance goal, you can identify the critical areas for optimization and make informed decisions on improving memory performance.\n",
      "What are some important guidelines to use to address my memory related problems?\n",
      " >>  When addressing memory related problems, it is important to take a systematic approach and consider all the factors that could be impacting performance. This includes understanding the top-level garbage collection metrics and their relation to the performance goal, collecting the appropriate metrics, and analyzing them in the context of the performance goal. This will help you identify the critical areas for optimization and make informed decisions on improving memory performance. Additionally, it is important to consider the memory usage of the application, the memory usage of the system, and the memory usage of the underlying hardware. By understanding the memory usage of each of these components, you can better identify potential issues and address them accordingly.\n"
     ]
    }
   ],
   "source": [
    "await Chat(\"How do I reduce my memory footprint? What are some topic metrics I should look at?\");\n",
    "await Chat(\"What metrics should I look at to address my memory issues.\");\n",
    "await Chat(\"What are some important guidelines to use to address my memory related problems?\"); "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Throughput Issues"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "dotnet_interactive": {
     "language": "csharp"
    },
    "polyglot_notebook": {
     "kernelName": "csharp"
    },
    "vscode": {
     "languageId": "polyglot-notebook"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "My GC is slowing my application down. What should I do?\n",
      " >>  If your GC is slowing down your application, you should first investigate the cause of the slowdown. You can do this by looking at the GC logs to see if there are any issues with the GC itself, or if there are any other performance issues that could be causing the slowdown. You can also use a profiler to identify any bottlenecks in your application code. Once you have identified the cause of the slowdown, you can take steps to address it, such as optimizing your code, tuning the GC parameters, or using a different GC algorithm.\n",
      "How should I address throughput issues?\n",
      " >>  To address throughput issues, performance engineers should first identify the root cause of the issue. This can be done by monitoring metrics such as % Pause time in GC and % CPU time in GC. If the issue is related to GC, then optimizing GC parameters such as heap size, GC type, and GC frequency can help improve throughput. Additionally, optimizing application code and tuning the application’s threading model can also help improve throughput. Finally, if the issue is related to hardware, then scaling up or scaling out the application can help improve throughput.\n",
      "What are some ways to reduce my GC latency?\n",
      " >>  There are several ways to reduce GC latency, including optimizing the garbage collection algorithm, tuning the JVM parameters, and using a concurrent garbage collector. Optimizing the garbage collection algorithm involves selecting the most appropriate algorithm for the application's needs, such as using a generational garbage collector for applications with a large number of short-lived objects. Tuning the JVM parameters involves adjusting the heap size, garbage collection frequency, and other parameters to reduce the amount of time spent in garbage collection. Finally, using a concurrent garbage collector can reduce GC pauses by allowing the application to continue running while the garbage collector is running in the background.\n"
     ]
    }
   ],
   "source": [
    "await Chat(\"My GC is slowing my application down. What should I do?\");\n",
    "await Chat(\"How should I address throughput issues?\");\n",
    "await Chat(\"What are some ways to reduce my GC latency?\");"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Different GC Flavors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "dotnet_interactive": {
     "language": "csharp"
    },
    "polyglot_notebook": {
     "kernelName": "csharp"
    },
    "vscode": {
     "languageId": "polyglot-notebook"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "What's the difference between Workstation and Server GC?\n",
      " >>  The main difference between Workstation GC (WKS GC) and Server GC (SVR GC) in .NET is the way they are optimized for different workloads. WKS GC is designed for workstation or client scenarios where the application shares the machine with other processes, while SVR GC is optimized for server workloads where the application is the dominant process on the machine and handles multiple user threads. \n",
      "\n",
      "WKS GC has a single heap, while SVR GC has one heap per logical core. Additionally, SVR GC threads have their priority set to `THREAD_PRIORITY_HIGHEST`, which allows them to preempt lower-priority threads. WKS GC runs on the user thread that triggered the GC, typically at normal priority. SVR GC threads are also hard affinitized to logical cores, ensuring better utilization of available CPU resources. \n",
      "\n",
      "The choice between WKS GC and SVR GC depends on the nature of the workload and the specific requirements of the application. SVR GC is particularly suited for server scenarios with high thread concurrency, while WKS GC is more suitable for client applications.\n",
      "What is background GC?\n",
      " >>  Background GC is a type of garbage collection in .NET that runs concurrently with user threads in order to minimize pauses caused by full GCs. During Background GC, only sweeping GCs are performed, meaning objects are not compacted. The free list built during Background GC is used by younger generation GCs to accommodate survivors. This helps to improve the memory performance of the application and optimize the GC behavior.\n",
      "Will WKS work better for my application than SVR?\n",
      " >>  It depends on the nature of your application and the specific requirements. WKS GC is typically used for workstation or client scenarios where the application shares the machine with other processes, while SVR GC is optimized for server workloads where the application is the dominant process on the machine and handles multiple user threads. If your application is a client application with low thread concurrency, then WKS GC may be a better choice. However, if your application is a server application with high thread concurrency, then SVR GC may be a better choice. Ultimately, it is important to consider the specific requirements of your application and the nature of the workload to determine which GC flavor is best suited for your needs.\n"
     ]
    }
   ],
   "source": [
    "await Chat(\"What's the difference between Workstation and Server GC?\");\n",
    "await Chat(\"What is background GC?\");\n",
    "await Chat(\"Will WKS work better for my application than SVR?\");"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Debugging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "dotnet_interactive": {
     "language": "csharp"
    },
    "polyglot_notebook": {
     "kernelName": "csharp"
    },
    "vscode": {
     "languageId": "polyglot-notebook"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table><tbody><tr><td><img src=\"data:image/png;base64, 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\" width=\"125em\"></img></td><td style=\"line-height:.8em\"><p style=\"font-size:1.5em\"><b>.NET Interactive</b></p><p>&#169; 2020 Microsoft Corporation</p><p><b>Version: </b>1.0.425803+1db2979099d0272660e1497cae9b9af1238db42f</p><p><b>Library version: </b>1.0.0-beta.23258.3+1db2979099d0272660e1497cae9b9af1238db42f</p><p><b>Build date: </b>2023-05-12T10:30:52.4965699Z</p><p><a href=\"https://github.com/dotnet/interactive\">https://github.com/dotnet/interactive</a></p></td></tr></tbody></table>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "using System.Diagnostics;\n",
    "\n",
    "#!about"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
